=title Speed up calculation by running in parallel
=timestamp 2016-07-12T08:30:01
=indexes Parallel::ForkManager, fork
=status show
=author szabgab
=archive 1
=comments_disqus_enable 1

=abstract start

In this example we have a bunch of numbers. We need to make some heavy calculation on each number (using our <hl>calc</hl> function),
and then collect the results in a hash where the keys are the original numbers and the values are the results.

=abstract end

For the sake of our example the "heavy computation" is generating and summing up lots of random numbers.

<h2>The linear solution</h2>

This is quite simple to do in linear code. We just need to iterate over the elements of the original array that holds the
input numbers and call the <hl>calc</hl> function on each one of them. When the function is done it returns the result that we
can then assign to the appropriate element in the hash.

<include file="examples/calc_no_fork.pl">

(If it is unclear what is in the <hl>@numbers</hl> array and how it is generated then use the <hl>Dumper</hl> function
to print the content of <hl>@numbers</hl> right after it was created and read about
<a href="/transforming-a-perl-array-using-map">map in Perl</a>.

We can run this code using the <hl>time</hl> program of the Unix/Linux shell:

<code>
$ time perl calc_no_fork.pl
</code>

The result on my computer was:

<code>
real    0m21.032s
</code>

It took 21 seconds to do all the calculations.

While the program was running I've also used the <hl>htop</hl> program in another console and saw that none of the 4 cores of
my computer is fully used.

<img src="/img/calc_no_fork.png" title="CPU load when running linear">

I think the reason that none of them is fully used is that the operating system moves the process around form CPU to CPU, but I am not 100% sure in this.

<h2>Using fork</h2>

In order to allow the computer to better utilize all its resources we could use either <hl>threads</hl> or <a href="/fork">fork</a>.
As <hl>threads</hl> are <a href="https://metacpan.org/pod/threads#WARNING">not a recommended technique in Perl</a> we opt to use <hl>fork</hl> as described in the article on
<a href="https://perlmaven.com/fork">Using fork to spread load to multiple cores</a>. The problem, as it is also mentioned at the end of
that article is that forked processes don't have shared memory, so the forked process cannot simple write back to the common <hl>%results</hl>
hash. That's where the module <a href="https://metacpan.org/pod/Parallel::ForkManager">Parallel::ForkManager</a> comes into play.

It is a wrapper around the regular <hl>fork</hl> function of Perl that provides us with various nice extra services. Including the
possibility to return data from the child processes to the parent process that launched them.

<include file="examples/calc_fork_manager.pl">

The code starts with the creation of the Parallel::ForkManager object and setting the maximum number of parallel child processes.

<code>
my $pm = Parallel::ForkManager->new($forks);
</code>

Then we create an anonymous function (a <hl>sub</hl> without a name) and pass it to the <hl>run_on_finish</hl> method of Parallel::ForkManager.
This function will be called once for each child process immediately as the child process terminates. It receives a number of parameters, but the
one that is interesting to us now is the 6th, the last parameter which we assigned to the <hl>$data_structure_reference</hl> variable.

This variable will hold everything we sent back from the child process. In our case that will be a hash reference with two keys. "input" will
contain the value from the original <hl>@numbers</hl> array the specific child process is dealing with. The "result" will contain the value
returned by the <hl>calc()</hl> function.

<code>
$pm->run_on_finish( sub {
    my ($pid, $exit_code, $ident, $exit_signal, $core_dump, $data_structure_reference) = @_;
    my $q = $data_structure_reference->{input};
    $results{$q} = $data_structure_reference->{result};
});
</code>

Then comes the main part of the code.

We have a simple <hl>foreach</hl> loop iterating over the <hl>@numbers</hl> array.
For each iteration we call <hl>my $pid = $pm->start and next;</hl> This will try to create
a new fork. 
If it is successful then at this point two processes will continue to run almost exactly the same way:
the value returned by the <hl>start</hl> method is assigned to <hl>$pid</hl>.
There is however a small difference in the two processes.

In the <b>parent process</b>, this value is going to be the process ID of the child process, a non-zero number,
and therefore the right-hand side of the <hl>and</hl> boolean operator
will be evaluated and the main process will go to the <hl>next</hl> iteration of the <hl>foreach</hl> loop.

In the <b>child process</b> the value returned by <hl>start</hl> will be 0. Which is false. Which means the right-hand side
of the <hl>and</hl> operator will not be executed. In the child process the next evaluated statement will be the
<hl>calc($q);</hl>. While the child process is calculating using one of the CPUs of the computer,
the main process can run using the other CPU and it can create more child-processes.

The Parallel::Forkmanager will also count how many child processes have been forked and if we reach the value passed to the <hl>new</hl>
constructor then the <hl>start</hl> command will wait till one of the earlier child-processes finishes and will only fork a new
child-process after that.

In the meantime all the child processes are running on one of the CPUs of the computer. When one of them finishes the <hl>calc</hl> function
it will call the <hl>finish</hl> method of Parallel::Forkmanager and it will pass to it two values. The first one is the exit code it
wishes to have. 0 means success. The second one is a reference to a data structure it wishes to send back to the main process.
This is the data structure we have used in the anonymous subroutine in <hl>$data_structure_reference</hl>.

<code>
foreach my $q (@numbers) {
    my $pid = $pm->start and next;
    my $res = calc($q);
    $pm->finish(0, { result => $res, input => $q });
}
$pm->wait_all_children;
</code>

The call to <hl>wait_all_children</hl> makes sure that the parent process will indeed wait till all the processes it created have finished
and will only continue running once that happened and once it had a chance to run the respective <hl>run_on_finish</hl> function.


We can run this script as

<code>
time perl ~/work/perlmaven.com/examples/calc_fork_manager.pl 8
</code>

The result is about twice as fast as the linear version:

<code>
real    0m11.138s
</code>

At the same time <hl>htop</hl> shows that all the CPUs are saturated.

<img src="/img/calc_fork_manager.png" title="CPU load when running with Parallel::ForkManager">


In some other measurements I've seen a 3-time speedup, but I think you can't expect anything better with a 4-core machine.
After all there are many other tasks running in the system, so we don't really have 4 times more free CPU power than
earlier, and the whole forking and managing the communication has some overhead.


<h2>Combined example</h2>

Just in case you'd like to tweak the calc() function and would like to further experiment with this code,
I've included a version of the two scripts combined together. If you run it without any parameter
it will run the linear version. If you run it with any positive number, it will use that many parallel child processes.

<include file="examples/calc_fork_manager_full.pl">

BTW, the "DATA_LOOP" in this example is not really needed, it only tries to make the code a bit more readable.

